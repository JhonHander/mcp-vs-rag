# üìù Implementaci√≥n de L√≠mites para Contexto MCP

## üéØ Problema Resuelto

Anteriormente, las b√∫squedas MCP (Tavily y DuckDuckGo) devolv√≠an demasiado contexto, causando:
- ‚ùå Alto consumo de tokens (2091-3275 tokens en los experimentos)
- ‚ùå Costos elevados ($0.023-$0.035 por experimento MCP vs $0.007-$0.012 para RAG)
- ‚ùå Riesgo de exceder l√≠mites de contexto del LLM

## ‚úÖ Soluci√≥n Implementada

### 1. **Archivo de Configuraci√≥n Centralizado**
**`src/config/mcp_config.py`**

```python
MCP_SEARCH_LIMITS = {
    "tavily": {
        "max_results": 3,        # Reducido de ~5-10 por defecto
        "search_depth": "basic"  # "basic" en lugar de "advanced"
    },
    "duckduckgo": {
        "max_results": 3         # Reducido de ~10 por defecto
    }
}

MAX_CONTEXT_LENGTH = 3000  # ~750 tokens aproximadamente
```

### 2. **B√∫squeda MCP Limitada**
**`src/workflow/main_workflow.py` - funci√≥n `search_mcp_context()`**

Ahora la b√∫squeda:
1. ‚úÖ Aplica l√≠mites configurables por servidor (`max_results`, `search_depth`)
2. ‚úÖ Trunca contexto si excede 3000 caracteres
3. ‚úÖ Registra cuando hay truncamiento para an√°lisis

**Antes:**
```python
result = await search_tool.ainvoke({"query": state["prompt"]})
return {"mcp_context": str(result)}
```

**Despu√©s:**
```python
base_params = {"query": state["prompt"]}
server_config = get_mcp_search_config(state["mcp_server"])
search_params = {**base_params, **server_config}

result = await search_tool.ainvoke(search_params)
was_truncated, final_context = should_truncate_context(str(result))
return {"mcp_context": final_context}
```

## üìä Impacto Esperado

### Reducci√≥n de Tokens Estimada:

| M√©trica | Antes | Despu√©s | Reducci√≥n |
|---------|-------|---------|-----------|
| **Tokens MCP (promedio)** | 1,000-1,500 | 400-700 | ~50-60% |
| **Costo MCP por experimento** | $0.024-$0.035 | $0.010-$0.018 | ~50-60% |
| **Context length** | Ilimitado | Max 3,000 chars | Controlado |

### Ejemplo Real (Config 2: GPT-5 + DuckDuckGo):
- **Antes**: 1,398 input tokens ‚Üí $0.007 input + $0.028 output = **$0.035 total**
- **Despu√©s (estimado)**: ~600 input tokens ‚Üí $0.003 input + $0.015 output = **~$0.018 total**

## üéöÔ∏è Configuraci√≥n Ajustable

Puedes modificar los l√≠mites en `src/config/mcp_config.py`:

```python
# Para resultados m√°s completos (m√°s tokens, m√°s costo):
"max_results": 5,
"search_depth": "advanced"  # Solo Tavily
MAX_CONTEXT_LENGTH = 5000

# Para resultados m√°s concisos (menos tokens, menos costo):
"max_results": 2,
"search_depth": "basic"
MAX_CONTEXT_LENGTH = 2000
```

## üìÅ Archivos Modificados

1. ‚úÖ **`src/config/mcp_config.py`** (NUEVO)
   - Configuraci√≥n centralizada de l√≠mites MCP
   - Funciones helper: `get_mcp_search_config()`, `should_truncate_context()`

2. ‚úÖ **`src/config/__init__.py`** (NUEVO)
   - M√≥dulo de configuraci√≥n

3. ‚úÖ **`src/workflow/main_workflow.py`** (MODIFICADO)
   - Importa configuraci√≥n MCP
   - Aplica l√≠mites en `search_mcp_context()`
   - Registra truncamientos

## üöÄ Pr√≥ximos Pasos

1. **Probar los nuevos l√≠mites**:
   ```bash
   python run_experiment.py 1
   ```

2. **Verificar reducci√≥n de costos**:
   - Revisar `cost_summary` en el JSON de salida
   - Comparar con resultados anteriores

3. **Ajustar si es necesario**:
   - Si las respuestas MCP pierden calidad ‚Üí aumentar `max_results` a 4-5
   - Si los costos siguen altos ‚Üí reducir `MAX_CONTEXT_LENGTH` a 2000

## üîç Monitoreo

El sistema ahora imprime logs durante la ejecuci√≥n:

```
üîç MCP Search (tavily): {'query': '...', 'max_results': 3, 'search_depth': 'basic'}
‚ö†Ô∏è  Context truncated from 4521 to 3000 chars
```

Esto te ayuda a ver cu√°ndo y cu√°nto se est√° truncando el contexto.

## üìå Notas Importantes

- ‚úÖ **No afecta RAG**: Los l√≠mites solo aplican a b√∫squedas MCP
- ‚úÖ **No afecta RAGAS**: La evaluaci√≥n no cambi√≥
- ‚úÖ **Tracking de costos intacto**: Sigue funcionando normalmente
- ‚úÖ **Retrocompatible**: Si no existe config, usa valores por defecto seguros

## üí° Recomendaciones

**Para producci√≥n:**
- Tavily: `max_results=3`, `search_depth="basic"` (balance calidad/costo)
- DuckDuckGo: `max_results=3` (m√°s econ√≥mico)
- MAX_CONTEXT_LENGTH: 3000 (suficiente para respuestas completas)

**Para m√°xima calidad (experimentaci√≥n):**
- Tavily: `max_results=5`, `search_depth="advanced"`
- DuckDuckGo: `max_results=5`
- MAX_CONTEXT_LENGTH: 5000

**Para m√≠nimo costo:**
- Tavily: `max_results=2`, `search_depth="basic"`
- DuckDuckGo: `max_results=2`
- MAX_CONTEXT_LENGTH: 2000
